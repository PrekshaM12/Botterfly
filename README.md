# ðŸ¦‹ Botterfly

**Botterfly is a fully-local AI help-desk assistant** that turns any folder of Markdown FAQs into instant answers.  
No cloud calls, no API keys requiredâ€”everything runs on-device using open-source models.

|                           | |
|---------------------------|----------------------------------------------------------------|
| **Tech stack**           | MiniLM sentence-transformer Â· ChromaDB Â· Llama 2-7B (Ollama) Â· LangChain Core |
| **Runs on**              | macOS / Linux laptop with â‰¥ 8 GB RAM (Apple Silicon or x86)     |
| **Latency**              | ~400â€“800 ms end-to-end on an M-series Mac                       |
| **Cost**                 | **\$0** (all models are free & local)                          |

---

## âœ¨ Features

* **Offline RAG** â€“ embeds your Markdown docs with MiniLM (Hugging Face) and stores vectors in Chroma.
* **Confidence gate** â€“ skips replies when similarity distance > 1.3 to avoid hallucinations.
* **Concise answers** â€“ prompt limits to â‰¤ 45 words, perfect for chat or desktop pop-ups.
* **Swappable LLM** â€“ default is `llama2:7b`; drop in `mistral:7b` or `llama2:13b` by editing one line.
* **100 % open source** â€“ no telemetry, no hidden keys.

---

## ðŸš€ Quick start

```bash
# 1  Clone repo & enter
git clone https://github.com/your-user/botterfly.git
cd botterfly

# 2  Create Python venv
python3 -m venv .venv
source .venv/bin/activate

# 3  Install deps
pip install -r requirements.txt   # langchain-core, langchain-huggingface, chromadb, sentence-transformers

# 4  Install Ollama & pull the LLM
brew install ollama               # or download the .dmg from ollama.ai
ollama pull llama2:7b

# 5  Embed your knowledge base
python scripts/embed_kb.py        # reads every *.md in kb/ and builds chroma_store/

# 6  Chat in Terminal
python scripts/process_ticket.py
